{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\pydub\\utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlockBlobService\n",
    "from urllib2 import urlopen\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import db_to_float\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_name = 'cfvtes9c07'\n",
    "account_key = 'DSTJn6a1dS9aaoJuuw6ZOsnrsiW9V1jODJyHtekkYkc3BWofGVQjS6/ICWO7v51VUpTHSoiZXVvDI66uqTnOJQ=='\n",
    "audio_container_name = \"audiocontainer\"\n",
    "block_blob_service = BlockBlobService(account_name, account_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_name = \"english-2Minutes.wav\"\n",
    "audio_file_url = r\"https://{0}.blob.core.windows.net/{1}/{2}\".format(account_name, audio_container_name, audio_file_name)\n",
    "audio_file_object = urlopen(audio_file_url)\n",
    "audio_segment = AudioSegment(audio_file_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_silence(audio_segment, min_silence_len=1000, silence_thresh=-16, seek_step=1):\n",
    "    seg_len = len(audio_segment)\n",
    "\n",
    "    # you can't have a silent portion of a sound that is longer than the sound\n",
    "    if seg_len < min_silence_len:\n",
    "        return []\n",
    "\n",
    "    # convert silence threshold to a float value (so we can compare it to rms)\n",
    "    silence_thresh = db_to_float(silence_thresh) * audio_segment.max_possible_amplitude\n",
    "\n",
    "    silence_starts = []\n",
    "\n",
    "    # check successive (1 sec by default) chunk of sound for silence\n",
    "    # try a chunk at every \"seek step\" (or every chunk for a seek step == 1)\n",
    "    last_slice_start = seg_len - min_silence_len\n",
    "    slice_starts = range(0, last_slice_start + 1, seek_step)\n",
    "\n",
    "    # guarantee last_slice_start is included in the range\n",
    "    # to make sure the last portion of the audio is seached\n",
    "    if last_slice_start % seek_step:\n",
    "        slice_starts = itertools.chain(slice_starts, [last_slice_start])\n",
    "\n",
    "    for i in slice_starts:\n",
    "        audio_slice = audio_segment[i:i + min_silence_len]\n",
    "        if audio_slice.rms <= silence_thresh:\n",
    "            silence_starts.append(i)\n",
    "    \n",
    "    if not silence_starts:\n",
    "        return []\n",
    "\n",
    "    silent_ranges = []\n",
    "\n",
    "    prev_i = silence_starts.pop(0)\n",
    "    current_range_start = prev_i\n",
    "\n",
    "    for silence_start_i in silence_starts:\n",
    "        continuous = (silence_start_i == prev_i + 1)\n",
    "\n",
    "        silence_has_gap = silence_start_i > (prev_i + min_silence_len)\n",
    "\n",
    "        if not continuous and silence_has_gap:\n",
    "            silent_ranges.append([current_range_start, prev_i + min_silence_len])\n",
    "            current_range_start = silence_start_i\n",
    "        prev_i = silence_start_i\n",
    "\n",
    "    silent_ranges.append([current_range_start, prev_i + min_silence_len])\n",
    "\n",
    "    return silent_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_nonsilent(audio_segment, min_silence_len=1000, silence_thresh=-16, seek_step=1):\n",
    "    silent_ranges = detect_silence(audio_segment, min_silence_len, silence_thresh, seek_step)\n",
    "    len_seg = len(audio_segment)\n",
    "\n",
    "    # if there is no silence, the whole thing is nonsilent\n",
    "    if not silent_ranges:\n",
    "        return [[0, len_seg]]\n",
    "\n",
    "    # short circuit when the whole audio segment is silent\n",
    "    if silent_ranges[0][0] == 0 and silent_ranges[0][1] == len_seg:\n",
    "        return []\n",
    "\n",
    "    prev_end_i = 0\n",
    "    nonsilent_ranges = []\n",
    "    for start_i, end_i in silent_ranges:\n",
    "        nonsilent_ranges.append([prev_end_i, start_i])\n",
    "        prev_end_i = end_i\n",
    "\n",
    "    if end_i != len_seg:\n",
    "        nonsilent_ranges.append([prev_end_i, len_seg])\n",
    "\n",
    "    if nonsilent_ranges[0] == [0, 0]:\n",
    "        nonsilent_ranges.pop(0)\n",
    "\n",
    "    return nonsilent_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_silence(audio_segment, min_silence_len=1000, silence_thresh=-16, keep_silence=100,\n",
    "                     seek_step=1):\n",
    "    not_silence_ranges = detect_nonsilent(audio_segment, min_silence_len, silence_thresh, seek_step)\n",
    "\n",
    "    chunks = []\n",
    "    for start_i, end_i in not_silence_ranges:\n",
    "        start_i = max(0, start_i - keep_silence)\n",
    "        end_i += keep_silence\n",
    "        chunks.append(audio_segment[start_i:end_i])\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_silence_len = 1000\n",
    "silence_thresh = -36\n",
    "seek_step = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7000, 23000], [24000, 57000], [58000, 107000], [108000, 110000]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_nonsilent(audio_segment,\n",
    "                 min_silence_len=min_silence_len,\n",
    "                 silence_thresh=silence_thresh,\n",
    "                 seek_step=seek_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_silent_segments = split_on_silence(audio_segment,\n",
    "                                       min_silence_len=min_silence_len,\n",
    "                                       silence_thresh=silence_thresh,\n",
    "                                       seek_step=seek_step,\n",
    "                                       keep_silence=0)\n",
    "\n",
    "export_path = r\"C:\\Users\\Ron Michaeli\\Google Drive\\Drasco\\Final Project\\Development\\Audio Splitter\"\n",
    "i = 1\n",
    "for non_silent_segment in non_silent_segments:\n",
    "    non_silent_segment.export(export_path + r\"\\{0}.wav\".format(i), format=\"wav\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
